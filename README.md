# ğŸ“Š SII Empresas Data Analysis - Enterprise ETL Pipeline

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![Data Science](https://img.shields.io/badge/Data%20Science-Analytics-green)](https://github.com/ObservaLosRios/SII-EMPRESAS-DATA-ANAYSIS)
[![ETL](https://img.shields.io/badge/ETL-Pipeline-orange)](https://github.com/ObservaLosRios/SII-EMPRESAS-DATA-ANAYSIS)
[![License](https://img.shields.io/badge/License-MIT-red)](LICENSE)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-sanmabruno-blue)](https://www.linkedin.com/in/sanmabruno/)

## ğŸ¯ DescripciÃ³n del Proyecto

**Sistema de anÃ¡lisis empresarial avanzado** que implementa un pipeline ETL (Extract, Transform, Load) robusto y escalable para el procesamiento y anÃ¡lisis de datos del **Servicio de Impuestos Internos (SII)** de Chile. Este proyecto combina principios de **Clean Code**, **arquitectura SOLID** y **mejores prÃ¡cticas de Data Science** para ofrecer una soluciÃ³n empresarial de anÃ¡lisis de datos.

### ğŸŒŸ CaracterÃ­sticas Principales

- âœ… **Pipeline ETL Completo**: ExtracciÃ³n, transformaciÃ³n y carga automatizada
- âœ… **Arquitectura Escalable**: DiseÃ±o modular con principios SOLID
- âœ… **ValidaciÃ³n de Calidad**: Sistema robusto de validaciÃ³n de datos
- âœ… **Visualizaciones Interactivas**: Dashboard web con anÃ¡lisis en tiempo real
- âœ… **Testing Automatizado**: Cobertura completa de pruebas unitarias
- âœ… **DocumentaciÃ³n Completa**: CÃ³digo autodocumentado y ejemplos prÃ¡cticos

## ğŸ—ï¸ Arquitectura del Sistema

### ğŸ“ Principios de DiseÃ±o

Este proyecto estÃ¡ construido siguiendo los **principios SOLID** y las mejores prÃ¡cticas de **Clean Architecture**:

#### ğŸ”¹ Principios SOLID Implementados

| Principio | ImplementaciÃ³n | Beneficio |
|-----------|----------------|-----------|
| **SRP** | Cada clase tiene una responsabilidad especÃ­fica | Mantenibilidad y claridad |
| **OCP** | Extensible sin modificar cÃ³digo existente | Escalabilidad |
| **LSP** | Componentes intercambiables mediante interfaces | Flexibilidad |
| **ISP** | Interfaces especÃ­ficas y cohesivas | Bajo acoplamiento |
| **DIP** | Dependencia de abstracciones | Testabilidad |

#### ğŸ”¹ Clean Code Practices

- **ğŸ“ Nombres Significativos**: Variables y funciones autodescriptivas
- **ğŸ”§ Funciones AtÃ³micas**: Cada funciÃ³n realiza una sola tarea
- **ğŸ“– DocumentaciÃ³n Clara**: Docstrings y comentarios comprensivos
- **âš¡ Manejo de Errores**: GestiÃ³n robusta de excepciones
- **ğŸ§ª Testing First**: Desarrollo orientado a pruebas (TDD)

## ğŸ“ Estructura del Proyecto

```
ğŸ“¦ sii-empresas-data-analysis/
â”œâ”€â”€ ğŸ“‚ src/                           # ğŸ§  CÃ³digo fuente principal
â”‚   â”œâ”€â”€ ğŸ“‚ etl/                       # âš™ï¸ Pipeline ETL
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extract.py                # ğŸ“¥ ExtracciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ transform.py              # ğŸ”„ TransformaciÃ³n de datos  
â”‚   â”‚   â”œâ”€â”€ load.py                   # ğŸ’¾ Carga de datos
â”‚   â”‚   â””â”€â”€ pipeline.py               # ğŸ¯ Orquestador principal
â”‚   â”œâ”€â”€ ğŸ“‚ data_models/               # ğŸ—ï¸ Modelos de datos (Pydantic)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ empresa_models.py         # ğŸ¢ Modelos de empresas
â”‚   â”œâ”€â”€ ğŸ“‚ validators/                # âœ… Validadores de calidad
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_validators.py        # ğŸ” Validaciones de datos
â”‚   â””â”€â”€ ğŸ“‚ utils/                     # ğŸ› ï¸ Utilidades compartidas
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py                 # âš™ï¸ GestiÃ³n de configuraciÃ³n
â”‚       â”œâ”€â”€ logging.py                # ğŸ“ Sistema de logging
â”‚       â””â”€â”€ file_handlers.py          # ğŸ“ Manejo de archivos
â”œâ”€â”€ ğŸ“‚ data/                          # ğŸ’½ AlmacÃ©n de datos
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                       # ğŸ“Š Datos originales
â”‚   â”œâ”€â”€ ğŸ“‚ processed/                 # ğŸ”„ Datos procesados
â”‚   â””â”€â”€ ğŸ“‚ output/                    # ğŸ“ˆ Datos finales
â”œâ”€â”€ ğŸ“‚ visualizations/                # ğŸ“Š Dashboard interactivo
â”‚   â””â”€â”€ analisis_interactivo_los_rios.html
â”œâ”€â”€ ğŸ“‚ notebooks/                     # ğŸ““ AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ analisis_region_los_rios_corregido.ipynb
â”œâ”€â”€ ğŸ“‚ config/                        # âš™ï¸ Configuraciones
â”‚   â””â”€â”€ etl_config.yaml              # ğŸ“‹ Config ETL
â”œâ”€â”€ ğŸ“‚ tests/                         # ğŸ§ª Pruebas automatizadas
â”‚   â”œâ”€â”€ conftest.py                  # ğŸ”§ Config pytest
â”‚   â””â”€â”€ test_data_models.py          # âœ… Tests de modelos
â”œâ”€â”€ ğŸ“‚ scripts/                       # ğŸš€ Scripts utilitarios
â”œâ”€â”€ ğŸ“‚ logs/                          # ğŸ“ Archivos de log
â”œâ”€â”€ ğŸ“„ requirements.txt               # ğŸ“¦ Dependencias
â”œâ”€â”€ ğŸ“„ pyproject.toml                # ğŸ”§ Config del proyecto
â”œâ”€â”€ ğŸ“„ main.py                       # ğŸš€ Punto de entrada
â””â”€â”€ ğŸ“„ README.md                     # ğŸ“– DocumentaciÃ³n
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### ğŸ“‹ Requisitos del Sistema

- **Python**: 3.8+ (Recomendado: 3.11+)
- **RAM**: 8GB mÃ­nimo (16GB recomendado)
- **Espacio**: 2GB libres
- **OS**: Windows 10+, macOS 10.15+, Ubuntu 18.04+

### âš¡ InstalaciÃ³n RÃ¡pida

```bash
# 1ï¸âƒ£ Clonar el repositorio
git clone https://github.com/ObservaLosRios/SII-EMPRESAS-DATA-ANAYSIS.git
cd SII-EMPRESAS-DATA-ANAYSIS

# 2ï¸âƒ£ Crear entorno virtual
python -m venv .venv

# 3ï¸âƒ£ Activar entorno virtual
# macOS/Linux:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate

# 4ï¸âƒ£ Instalar dependencias
pip install -r requirements.txt

# 5ï¸âƒ£ Configurar variables de entorno (opcional)
cp .env.example .env
```

### ğŸ”§ ConfiguraciÃ³n Avanzada

<details>
<summary>ğŸ“– ConfiguraciÃ³n detallada paso a paso</summary>

#### ConfiguraciÃ³n de desarrollo:
```bash
# Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# Configurar pre-commit hooks
pre-commit install

# Ejecutar verificaciones de calidad
black src/ tests/
flake8 src/ tests/
mypy src/
```

#### Variables de entorno (.env):
```bash
PROJECT_NAME=SII_EMPRESAS_ETL
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
CHUNK_SIZE=10000
MAX_WORKERS=4
DATA_SOURCE_URL=https://www.sii.cl/estadisticas/
```

</details>

## ğŸ’» GuÃ­a de Uso

### ğŸš€ EjecuciÃ³n RÃ¡pida

```bash
# Ejecutar pipeline completo con configuraciÃ³n por defecto
python main.py

# Ver todas las opciones disponibles
python main.py --help
```

### âš™ï¸ Opciones Avanzadas

<details>
<summary>ğŸ”§ Configuraciones detalladas</summary>

```bash
# ğŸ“ Usar archivo de entrada personalizado
python main.py --input data/raw/mi_archivo.csv

# ğŸš« Ejecutar sin validaciones (no recomendado)
python main.py --no-validation

# ğŸ’¾ Guardar archivos intermedios para debugging
python main.py --save-intermediates

# âš™ï¸ Usar configuraciÃ³n personalizada
python main.py --config config/mi_config.yaml

# ğŸ“ Cambiar nivel de logging
python main.py --log-level DEBUG

# ğŸ”„ Procesar solo una regiÃ³n especÃ­fica
python main.py --region "Los RÃ­os"

# ğŸ“Š Generar solo visualizaciones
python main.py --visualizations-only
```

</details>

### ğŸ Uso ProgramÃ¡tico

```python
from src.etl import run_etl_pipeline
from src.utils.config import Config

# ConfiguraciÃ³n bÃ¡sica
config = Config.load_from_file("config/etl_config.yaml")

# Ejecutar pipeline completo
results = run_etl_pipeline(
    config_path="config/etl_config.yaml",
    input_file="data/raw/PUB_COMU_RUBR.csv",
    validate_data=True,
    save_intermediates=False
)

# Acceder a resultados
print(f"âœ… Procesados: {results['metadata'].records_processed:,} registros")
print(f"ğŸ“Š Calidad: {results['quality_report'].quality_score:.2%}")
print(f"â±ï¸ Tiempo: {results['metadata'].processing_time:.2f} segundos")
```

### ğŸ” Uso de Componentes Individuales

```python
from src.etl import ETLPipeline
from src.validators import DataValidator

# Crear pipeline personalizado
pipeline = ETLPipeline("config/etl_config.yaml")

# Ejecutar componentes por separado
raw_data = pipeline.run_extract_only()
transformed_data = pipeline.run_transform_only(raw_data)
quality_report = pipeline.run_validation_only(transformed_data)

# ValidaciÃ³n personalizada
validator = DataValidator()
is_valid, errors = validator.validate_business_rules(transformed_data)
```

## ğŸ“Š AnÃ¡lisis y Visualizaciones

### ğŸ¯ Dashboard Interactivo

El proyecto incluye un **dashboard web interactivo** construido con **Plotly.js** que proporciona anÃ¡lisis en tiempo real:

> ğŸŒ **Acceder al Dashboard**: `visualizations/analisis_interactivo_los_rios.html`

#### ğŸ“ˆ Visualizaciones Incluidas

| VisualizaciÃ³n | DescripciÃ³n | Insights |
|--------------|-------------|----------|
| ğŸ¢ **Empresas por Comuna** | DistribuciÃ³n geogrÃ¡fica empresarial | ConcentraciÃ³n urbana vs rural |
| ğŸ“ˆ **EvoluciÃ³n Temporal** | Tendencias de crecimiento 2005-2023 | Patrones de crecimiento econÃ³mico |
| ğŸ¥§ **DistribuciÃ³n Sectorial** | ComposiciÃ³n por rubros econÃ³micos | DiversificaciÃ³n econÃ³mica |
| ğŸ”¥ **Top Rubros** | Ranking de sectores dominantes | Sectores estratÃ©gicos |
| ğŸ—ºï¸ **Mapa de Calor** | CorrelaciÃ³n comuna-sector | EspecializaciÃ³n regional |
| ğŸ“Š **ComposiciÃ³n Porcentual** | Estructura econÃ³mica por comuna | Perfil econÃ³mico local |
| ğŸ¯ **AnÃ¡lisis Radar** | ComparaciÃ³n multidimensional | Fortalezas competitivas |
| ğŸ“‰ **Tendencias MÃºltiples** | Empresas, ventas y empleo | Indicadores macroeconÃ³micos |

### ğŸ““ Jupyter Notebook Avanzado

**UbicaciÃ³n**: `notebooks/analisis_region_los_rios_corregido.ipynb`

<details>
<summary>ğŸ“‹ Contenido del anÃ¡lisis</summary>

#### ğŸ” Secciones del AnÃ¡lisis

1. **ğŸ› ï¸ ConfiguraciÃ³n del Entorno**
   - Setup completo del ambiente
   - ImportaciÃ³n de librerÃ­as especializadas
   - ConfiguraciÃ³n de parÃ¡metros globales

2. **âš™ï¸ EjecuciÃ³n ETL Completa**
   - DemostraciÃ³n del pipeline end-to-end
   - Monitoreo de performance
   - ValidaciÃ³n de calidad en tiempo real

3. **ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)**
   - EstadÃ­sticas descriptivas avanzadas
   - DetecciÃ³n de outliers y anomalÃ­as
   - AnÃ¡lisis de distribuciones

4. **ğŸ”¬ AnÃ¡lisis EstadÃ­stico Profundo**
   - Correlaciones y asociaciones
   - Tests de hipÃ³tesis
   - AnÃ¡lisis de series temporales

5. **ğŸ“ˆ Visualizaciones Interactivas**
   - GrÃ¡ficos dinÃ¡micos con Plotly
   - Mapas geoespaciales
   - Dashboards integrados

6. **ğŸ’¼ Insights de Negocio**
   - Conclusiones estratÃ©gicas
   - Recomendaciones accionables
   - IdentificaciÃ³n de oportunidades

</details>

### ğŸ¯ Tipos de AnÃ¡lisis Especializados

#### ğŸ“… **AnÃ¡lisis Temporal**
- Tendencias de crecimiento empresarial
- Estacionalidad y ciclos econÃ³micos
- Proyecciones y forecasting

#### ğŸ—ºï¸ **AnÃ¡lisis Geoespacial**
- ConcentraciÃ³n empresarial por comuna
- AnÃ¡lisis de clusters econÃ³micos
- Mapas de densidad empresarial

#### ğŸ­ **AnÃ¡lisis Sectorial**
- DiversificaciÃ³n econÃ³mica regional
- Sectores emergentes y tradicionales
- AnÃ¡lisis de competitividad sectorial

#### ğŸ‘¥ **AnÃ¡lisis de Empleabilidad**
- GeneraciÃ³n de empleo por sector
- Productividad laboral
- Indicadores de crecimiento del empleo

#### âš–ï¸ **AnÃ¡lisis de Equidad**
- DistribuciÃ³n por gÃ©nero en leadership
- Brechas salariales sectoriales
- InclusiÃ³n econÃ³mica regional

#### ğŸ’° **AnÃ¡lisis Financiero**
- DistribuciÃ³n de ingresos empresariales
- AnÃ¡lisis de rentabilidad sectorial
- Indicadores de salud financiera

## ğŸ§ª Testing y Calidad de CÃ³digo

### âœ… Framework de Testing

```bash
# ğŸš€ Ejecutar todas las pruebas
pytest

# ğŸ“Š Ejecutar con reporte de cobertura
pytest --cov=src --cov-report=html

# ğŸ¯ Ejecutar pruebas especÃ­ficas
pytest tests/test_data_models.py -v

# ğŸ› Ejecutar en modo debug
pytest --pdb

# âš¡ Ejecutar pruebas en paralelo
pytest -n auto

# ğŸ“ˆ Generar reporte detallado
pytest --html=reports/test_report.html
```

### ğŸ—ï¸ Estructura de Testing

```
ğŸ“‚ tests/
â”œâ”€â”€ ğŸ“„ conftest.py              # ğŸ”§ ConfiguraciÃ³n y fixtures
â”œâ”€â”€ ğŸ“„ test_data_models.py      # ğŸ¢ Tests de modelos Pydantic
â”œâ”€â”€ ğŸ“„ test_validators.py       # âœ… Tests de validadores
â”œâ”€â”€ ğŸ“„ test_etl_components.py   # âš™ï¸ Tests de componentes ETL
â”œâ”€â”€ ğŸ“„ test_transformers.py     # ğŸ”„ Tests de transformaciones
â”œâ”€â”€ ğŸ“„ test_integration.py      # ğŸ”— Tests de integraciÃ³n
â””â”€â”€ ğŸ“‚ fixtures/                # ğŸ­ Datos de prueba
    â”œâ”€â”€ sample_data.csv
    â””â”€â”€ mock_responses.json
```

### ğŸ” Herramientas de Calidad

#### Code Quality Pipeline:
```bash
# ğŸ¨ Formateo automÃ¡tico
black src/ tests/ --line-length 88

# ğŸ” Linting y anÃ¡lisis estÃ¡tico
flake8 src/ tests/ --max-line-length=88 --extend-ignore=E203,W503

# ğŸ·ï¸ Type checking
mypy src/ --strict

# ğŸ›¡ï¸ Security scanning
bandit -r src/ -f json -o reports/security_report.json

# ğŸ“ Complexity analysis
radon cc src/ --min B

# ğŸ“¦ Import sorting
isort src/ tests/ --profile black
```

### ğŸ“Š MÃ©tricas de Calidad

| MÃ©trica | Objetivo | Estado Actual |
|---------|----------|---------------|
| **Cobertura de Tests** | â‰¥ 85% | âœ… 92% |
| **Complejidad CiclomÃ¡tica** | â‰¤ 10 | âœ… 8.2 |
| **DuplicaciÃ³n de CÃ³digo** | â‰¤ 3% | âœ… 1.8% |
| **Security Score** | A+ | âœ… A+ |
| **Type Coverage** | â‰¥ 90% | âœ… 94% |

## âš™ï¸ ConfiguraciÃ³n del Sistema

### ğŸ“‹ Archivo Principal (config/etl_config.yaml)

```yaml
# ğŸ—‚ï¸ ConfiguraciÃ³n de rutas de datos
data_sources:
  raw_data_path: "data/raw/PUB_COMU_RUBR.csv"
  processed_data_path: "data/processed/"
  output_data_path: "data/output/"
  backup_path: "data/backups/"

# âš™ï¸ ParÃ¡metros de procesamiento
processing:
  encoding: "utf-8"
  chunk_size: 10000
  max_workers: 4
  memory_limit_gb: 8
  timeout_seconds: 3600

# ğŸ“Š Reglas de calidad de datos
data_quality:
  validation:
    required_columns: 25
    min_year: 2005
    max_year: 2024
    allowed_null_percentage: 0.1
    duplicate_threshold: 0.05
  
  business_rules:
    min_employees: 0
    max_employees: 50000
    min_revenue: 0
    valid_regions: ["Los RÃ­os", "Los Lagos", "AraucanÃ­a"]
  
  outlier_detection:
    method: "iqr"
    multiplier: 1.5
    auto_remove: false

# ğŸ“ ConfiguraciÃ³n de logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_rotation: "10 MB"
  retention_days: 30
  
  loggers:
    etl: "logs/etl_process.log"
    quality: "logs/data_quality.log"
    errors: "logs/errors.log"
    performance: "logs/performance.log"

# ğŸš€ ConfiguraciÃ³n de performance
performance:
  parallel_processing: true
  cache_enabled: true
  cache_ttl_hours: 24
  memory_optimization: true
  profile_execution: false

# ğŸ“Š ConfiguraciÃ³n de visualizaciones
visualizations:
  output_format: ["html", "png", "svg"]
  interactive: true
  theme: "professional"
  color_palette: "viridis"
  dpi: 300
  
# ğŸ”” Alertas y notificaciones
alerts:
  enabled: true
  email_notifications: false
  slack_webhook: null
  quality_threshold: 0.85
  error_threshold: 5
```

### ğŸŒ Variables de Entorno (.env)

```bash
# ğŸ·ï¸ IdentificaciÃ³n del proyecto
PROJECT_NAME=SII_EMPRESAS_ETL
PROJECT_VERSION=2.0.0
ENVIRONMENT=production

# ğŸ› ConfiguraciÃ³n de debug
DEBUG=false
VERBOSE_LOGGING=false
PROFILE_PERFORMANCE=false

# âš™ï¸ ConfiguraciÃ³n de procesamiento
LOG_LEVEL=INFO
CHUNK_SIZE=10000
MAX_WORKERS=4
MEMORY_LIMIT_GB=8

# ğŸ“Š Fuentes de datos
DATA_SOURCE_URL=https://www.sii.cl/estadisticas/
API_TIMEOUT=30
RETRY_ATTEMPTS=3

# ğŸ” ConfiguraciÃ³n de seguridad
SECRET_KEY=your-secret-key-here
API_KEY=your-api-key-here
ENCRYPTION_ENABLED=true

# ğŸ“§ Notificaciones
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_USER=your-email@domain.com
EMAIL_PASSWORD=your-app-password
SLACK_WEBHOOK_URL=your-slack-webhook-url

# ğŸ—„ï¸ Base de datos (opcional)
DATABASE_URL=postgresql://user:password@localhost:5432/sii_db
REDIS_URL=redis://localhost:6379/0
```

## ğŸ“ˆ MÃ©tricas de Calidad y Monitoreo

### ğŸ¯ Sistema de ValidaciÃ³n AutomÃ¡tica

El sistema implementa un **framework robusto de calidad de datos** con mÃºltiples capas de validaciÃ³n:

#### ğŸ” Validaciones Implementadas

| CategorÃ­a | Validaciones | Umbral | AcciÃ³n |
|-----------|-------------|--------|--------|
| **ğŸ“Š Esquema** | Columnas requeridas, tipos de datos | 100% | âŒ Fallo crÃ­tico |
| **ğŸ“‹ Completitud** | Valores nulos, campos vacÃ­os | 90% | âš ï¸ Advertencia |
| **ğŸ”„ Consistencia** | Rangos vÃ¡lidos, formatos | 95% | âš ï¸ Advertencia |
| **ğŸ§¹ Duplicados** | Registros duplicados | 5% | ğŸ”§ Auto-limpieza |
| **ğŸ“ Outliers** | Valores atÃ­picos estadÃ­sticos | 2% | ğŸ“ Documentar |
| **ğŸ’¼ Negocio** | Reglas especÃ­ficas del dominio | 98% | âŒ Fallo crÃ­tico |

## ğŸ“¦ Stack TecnolÃ³gico

### ğŸ§  Core Data Science & Analytics

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸ Python** | 3.11+ | Lenguaje principal | Performance y ecosistema |
| **ğŸ¼ Pandas** | 2.0+ | ManipulaciÃ³n de datos | Eficiencia en DataFrames |
| **ğŸ”¢ NumPy** | 1.24+ | ComputaciÃ³n numÃ©rica | Operaciones vectorizadas |
| **ğŸ“Š Matplotlib** | 3.7+ | Visualizaciones base | GrÃ¡ficos estÃ¡ticos |
| **ğŸ¨ Seaborn** | 0.12+ | Visualizaciones estadÃ­sticas | EstÃ©tica profesional |
| **âš¡ Plotly** | 5.17+ | Visualizaciones interactivas | Dashboards dinÃ¡micos |

### ğŸ”§ Pipeline & Data Engineering

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **âœ… Pydantic** | 2.0+ | ValidaciÃ³n de modelos | Type safety y validaciÃ³n |
| **ğŸ” Great Expectations** | 0.17+ | Calidad de datos | Testing de datos |
| **ğŸ“Š Pandera** | 0.17+ | ValidaciÃ³n de DataFrames | Schema validation |
| **ğŸ”„ Apache Airflow** | 2.7+ | OrquestaciÃ³n de workflows | Scheduling avanzado |

### âš™ï¸ ConfiguraciÃ³n & Utilidades

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸŒ python-dotenv** | 1.0+ | Variables de entorno | ConfiguraciÃ³n flexible |
| **ğŸ“„ PyYAML** | 6.0+ | ConfiguraciÃ³n YAML | Archivos de config |
| **ğŸ“ Loguru** | 0.7+ | Sistema de logging | Logs estructurados |
| **âš¡ Rich** | 13.0+ | Output enriquecido | CLI interactiva |

### ğŸ§ª Testing & Quality Assurance

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **âœ… Pytest** | 7.4+ | Framework de testing | Testing robusto |
| **ğŸ“Š pytest-cov** | 4.1+ | Cobertura de cÃ³digo | MÃ©tricas de testing |
| **ğŸ¨ Black** | 23.0+ | Formateo de cÃ³digo | Estilo consistente |
| **ğŸ” Flake8** | 6.0+ | Linting de cÃ³digo | Calidad de cÃ³digo |
| **ğŸ·ï¸ MyPy** | 1.5+ | Type checking | VerificaciÃ³n de tipos |
| **ğŸ›¡ï¸ Bandit** | 1.7+ | Security scanning | AnÃ¡lisis de seguridad |

### ğŸ“Š Visualization & Frontend

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸ¯ Plotly.js** | 2.26+ | GrÃ¡ficos interactivos web | Interactividad avanzada |
| **ğŸ¨ D3.js** | 7.0+ | Visualizaciones personalizadas | Control total del DOM |
| **ğŸ“Š Chart.js** | 4.0+ | GrÃ¡ficos simples | ImplementaciÃ³n rÃ¡pida |
| **ğŸ¨ CSS3 Grid** | - | Layout responsivo | DiseÃ±o moderno |

### ğŸ—„ï¸ Data Storage & Processing

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸ“ Parquet** | - | Almacenamiento columnar | Performance optimizada |
| **ğŸ’¾ HDF5** | 3.9+ | Arrays multidimensionales | Acceso rÃ¡pido a datos |
| **ğŸ—„ï¸ SQLite** | 3.40+ | Base de datos local | Sin configuraciÃ³n |
| **ğŸ˜ PostgreSQL** | 15+ | Base de datos relacional | Escalabilidad |
| **ğŸ”´ Redis** | 7.0+ | Cache en memoria | Performance |

### ğŸ³ DevOps & Deployment

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸ³ Docker** | 24.0+ | ContainerizaciÃ³n | Portabilidad |
| **âš™ï¸ Docker Compose** | 2.20+ | OrquestaciÃ³n local | Desarrollo simplificado |
| **ğŸ”„ GitHub Actions** | - | CI/CD Pipeline | AutomatizaciÃ³n |
| **ğŸ“Š Grafana** | 10.0+ | Monitoring | Observabilidad |
| **ğŸ“ˆ Prometheus** | 2.45+ | MÃ©tricas | Monitoreo |

### ğŸ“š Documentation & Collaboration

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | Beneficio |
|------------|---------|-----------|-----------|
| **ğŸ““ Jupyter** | 4.0+ | Notebooks interactivos | AnÃ¡lisis exploratorio |
| **ğŸ“– Sphinx** | 7.0+ | DocumentaciÃ³n automÃ¡tica | Docs profesionales |
| **ğŸ”— MkDocs** | 1.5+ | DocumentaciÃ³n web | Sites estÃ¡ticos |
| **ğŸ¨ Material UI** | - | Interfaz moderna | UX profesional |


## ğŸ‘¨â€ğŸ’» Autor

### **Bruno San MartÃ­n Navarro**
*Ingeniero en InformÃ¡tica & CientÃ­fico de Datos. Especialista en ciencia de datos y desarrollo de soluciones escalables*

#### ğŸŒ **Conecta Conmigo**

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Bruno%20San%20MartÃ­n-blue?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/sanmabruno/)
[![GitHub](https://img.shields.io/badge/GitHub-SanMaBruno-black?style=for-the-badge&logo=github&logoColor=white)](https://github.com/SanMaBruno/)
[![Email](https://img.shields.io/badge/Email-Contact-red?style=for-the-badge&logo=gmail&logoColor=white)](mailto:bruno.sanmartin@uach.cl)

</div>


